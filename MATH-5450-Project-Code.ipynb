{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Analytics - Final Project Code\n",
    "By: Dennis Goldenberg, Triet Vo, Kezia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Comparing Binomial Expansion Model to Gaussian Copula Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking average 10-year cumulative default probabilities from the insurance industry (1981-2021) based on S&P Ratings data, I can generate estimates for the homogeneous, correlated portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_assets = 100\n",
    "Notional = 10000000\n",
    "\n",
    "#Generate random Notional amounts\n",
    "np.random.seed(4)\n",
    "Notionals = np.random.uniform(low = .25 * Notional/num_assets, high = 1.75 * Notional/num_assets, size = num_assets)\n",
    "\n",
    "\n",
    "#recover number of names given defaults from 15 year data\n",
    "N_i = np.asarray([int(21/.173),int(15/.028),int(8/.1029), int(16/.1409)])\n",
    "\n",
    "#Generate default probabilities - 250 names rated BBB, BB, B, and C, 10 years into maturity\n",
    "rd_probs = np.asarray([.0131, .0243, .0811, .1105])\n",
    "D_i = np.asarray([int(N_i[i] * rd_probs[i]) for i in range(len(N_i))]) + 1\n",
    "\n",
    "default_probs = [rd_probs[0]] * int(num_assets/4) + [rd_probs[1]]*int(num_assets/4)\n",
    "default_probs = default_probs + [rd_probs[1]]*int(num_assets/4) + [rd_probs[3]]*int(num_assets/4)\n",
    "default_probs = np.asarray(default_probs)\n",
    "\n",
    "#calculate joint probabilities and default correlation\n",
    "joint_prob = np.empty(shape = (4,4))\n",
    "corr_mat = np.empty(shape = (4,4))\n",
    "for i in range(len(N_i)):\n",
    "    for j in range(len(N_i)):\n",
    "        if i == j:\n",
    "            joint_prob[i,j] = (D_i[i]**2)/(N_i[i]**2)\n",
    "            corr_mat[i,j] = (joint_prob[i,j] - (rd_probs[i]**2))/(rd_probs[i]*(1 - rd_probs[i]))\n",
    "        else:\n",
    "            joint_prob[i,j] = (D_i[i] * D_i[j])/(N_i[i]*N_i[j])\n",
    "            corr_mat[i,j] = (joint_prob[i,j] - (rd_probs[i]*rd_probs[j]))\n",
    "            corr_mat[i,j] = corr_mat[i,j]/np.sqrt(rd_probs[i]*(1 - rd_probs[i]) * rd_probs[j]*(1 - rd_probs[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability of defaults is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBB</th>\n",
       "      <th>BB</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BBB</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.001902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.010459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BBB        BB         B         C\n",
       "BBB  0.000273  0.000433  0.001503  0.001902\n",
       "BB   0.000433  0.000685  0.002379  0.003011\n",
       "B    0.001503  0.002379  0.008264  0.010459\n",
       "C    0.001902  0.003011  0.010459  0.013235"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = [\"BBB\", \"BB\", \"B\", \"C\"]\n",
    "jp_df = pd.DataFrame(data = joint_prob, columns = ratings, index = ratings)\n",
    "jp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the default correlation between two names, depending on their rating, is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBB</th>\n",
       "      <th>BB</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BBB</th>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>0.012736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BB</th>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.006740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.014182</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.017492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.012736</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>0.010428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BBB        BB         B         C\n",
       "BBB  0.007858  0.006523  0.014182  0.012736\n",
       "BB   0.006523  0.003977  0.009711  0.006740\n",
       "B    0.014182  0.009711  0.022641  0.017492\n",
       "C    0.012736  0.006740  0.017492  0.010428"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_df = pd.DataFrame(data = corr_mat, columns = ratings, index = ratings)\n",
    "rho_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate the estimate of the average correlation by calculating the paired correlation matrix and then using the formula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of correlation: 1.15 %\n"
     ]
    }
   ],
   "source": [
    "# calculated the paired correlation matrix\n",
    "paired_corr = np.empty(shape = (num_assets, num_assets))\n",
    "for k in range(num_assets):\n",
    "    if k < int(num_assets/4):\n",
    "        arr = [rho_df[\"BBB\"][\"BBB\"]]*int(num_assets/4) + [rho_df[\"BBB\"][\"BB\"]]*int(num_assets/4)\n",
    "        arr = arr + [rho_df[\"BBB\"][\"B\"]]*int(num_assets/4) + [rho_df[\"BBB\"][\"C\"]]*int(num_assets/4)\n",
    "        paired_corr[k] = arr\n",
    "    elif k < int(num_assets/2):\n",
    "        arr = [rho_df[\"BB\"][\"BBB\"]]*int(num_assets/4) + [rho_df[\"BB\"][\"BB\"]]*int(num_assets/4)\n",
    "        arr = arr + [rho_df[\"BB\"][\"B\"]]*int(num_assets/4) + [rho_df[\"BB\"][\"C\"]]*int(num_assets/4)\n",
    "        paired_corr[k] = arr\n",
    "    elif k < int(3 * num_assets / 4):\n",
    "        arr = [rho_df[\"B\"][\"BBB\"]]*int(num_assets/4) + [rho_df[\"B\"][\"BB\"]]*int(num_assets/4)\n",
    "        arr = arr + [rho_df[\"B\"][\"B\"]]*int(num_assets/4) + [rho_df[\"B\"][\"C\"]]*int(num_assets/4)\n",
    "        paired_corr[k] = arr\n",
    "    else:\n",
    "        arr = [rho_df[\"C\"][\"BBB\"]]*int(num_assets/4) + [rho_df[\"C\"][\"BB\"]]*int(num_assets/4)\n",
    "        arr = arr + [rho_df[\"C\"][\"B\"]]*int(num_assets/4) + [rho_df[\"C\"][\"C\"]]*int(num_assets/4)\n",
    "        paired_corr[k] = arr\n",
    "    paired_corr[k,k] = 1\n",
    "\n",
    "#generate all combinations of notionals and probability amounts\n",
    "Not_mult = np.matmul(np.expand_dims(Notionals, axis = 1),np.expand_dims(Notionals, axis = 0))\n",
    "def_mult = np.matmul(np.expand_dims(default_probs, axis = 1), np.expand_dims(default_probs, axis = 0))\n",
    "\n",
    "#Sum upper triangular and lower triangular elements for estimate:\n",
    "rho_est_num = np.sum(np.triu(paired_corr * Not_mult * def_mult)) - np.sum(np.diag(paired_corr * Not_mult * def_mult))\n",
    "rho_est_denom = np.sum(np.triu(Not_mult * def_mult)) - np.sum(np.diag(Not_mult * def_mult))\n",
    "rho_est = rho_est_num/rho_est_denom\n",
    "print(\"Estimate of correlation:\", np.round(rho_est, 5) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I estimate the correlated diversity score $D_\\rho$ with the formula provided in the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = np.sum(Notionals)/num_assets\n",
    "EUS = [np.min([Notionals[i]/AB, 1]) for i in range(len(Notionals))]\n",
    "D_indep = np.sum(EUS)\n",
    "D_rho = ((1 - rho_est)* D_indep)/(1 - (rho_est * D_indep))\n",
    "D_indep = int(round(D_indep,0))\n",
    "D_rho = int(round(D_rho,0))\n",
    "print(\"Independent Diversity Score:\", D_rho, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10875.70116160647"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surv_probs = 1 - default_probs\n",
    "#surv_mult = np.matmul(np.expand_dims(surv_probs, axis = 1), np.expand_dims(surv_probs, axis = 0))\n",
    "#D_est_num = np.sum(default_probs * Notionals)*np.sum(surv_mult * Notionals)*(1 - rho_est)\n",
    "#D_denom_1 = np.sum(paired_corr * np.sqrt(def_mult * surv_mult) * Not_mult)\n",
    "#D_denom_2 = rho_est * np.sum(default_probs * Notionals) * np.sum(surv_probs * Notionals)\n",
    "#D_rho_est = (D_est_num)/(D_denom_1 - D_denom_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing Gaussian Copula to Fudged Period by Period Copula"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M5450env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
